{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f918e3",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d4764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.62-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\rfriji\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.62\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807335d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009b8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b665889",
   "metadata": {},
   "source": [
    "# Reading image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "852f7afc",
   "metadata": {},
   "source": [
    "For reading an image, use the imread() function in OpenCV. Here’s the syntax:\n",
    "\n",
    "imread(filename, flags)\n",
    "\n",
    "It takes two arguments:\n",
    "\n",
    "The first argument is the image name, which requires a fully qualified pathname to the file.\n",
    "The second argument is an optional flag that lets you specify how the image should be represented.\n",
    "OpenCV offers several options for this flag, but those that are most common include:\n",
    "cv2.IMREAD_UNCHANGED  or -1\n",
    "cv2.IMREAD_GRAYSCALE  or 0\n",
    "cv2.IMREAD_COLOR  or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6dc606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grayscale = cv2.imread('Cat.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fe06f",
   "metadata": {},
   "source": [
    "# Displaying an image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdab1bf8",
   "metadata": {},
   "source": [
    "In OpenCV, you display an image using the imshow() function. Here’s the syntax:\n",
    "\n",
    "imshow(window_name, image)\n",
    "\n",
    "This function also takes two arguments:\n",
    "\n",
    "The first argument is the window name that will be displayed on the window.\n",
    " The second argument is the image that you want to display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6457ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[243 243 243]\n",
      "  [241 241 241]\n",
      "  [240 240 240]\n",
      "  ...\n",
      "  [246 246 246]\n",
      "  [246 246 246]\n",
      "  [246 246 246]]\n",
      "\n",
      " [[242 242 242]\n",
      "  [240 240 240]\n",
      "  [239 239 239]\n",
      "  ...\n",
      "  [245 245 245]\n",
      "  [245 245 245]\n",
      "  [245 245 245]]\n",
      "\n",
      " [[241 241 241]\n",
      "  [239 239 239]\n",
      "  [238 238 238]\n",
      "  ...\n",
      "  [245 245 245]\n",
      "  [245 245 245]\n",
      "  [245 245 245]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[227 233 246]\n",
      "  [224 230 243]\n",
      "  [223 229 242]\n",
      "  ...\n",
      "  [164 175 189]\n",
      "  [182 193 207]\n",
      "  [201 212 226]]\n",
      "\n",
      " [[227 233 246]\n",
      "  [224 230 243]\n",
      "  [223 229 242]\n",
      "  ...\n",
      "  [184 197 213]\n",
      "  [193 203 220]\n",
      "  [201 214 230]]\n",
      "\n",
      " [[222 230 243]\n",
      "  [220 228 241]\n",
      "  [219 227 240]\n",
      "  ...\n",
      "  [196 210 229]\n",
      "  [198 210 228]\n",
      "  [198 212 230]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6330492",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('graycsale image',img_grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6fe437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7007f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dcf77",
   "metadata": {},
   "source": [
    "# Writing an Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3563deb1",
   "metadata": {},
   "source": [
    "imwrite(filename, image).\n",
    "\n",
    "The first argument is the filename, which must include the filename extension (for example .png, .jpg etc). OpenCV uses this filename extension to specify the format of the file. \n",
    "The second argument is the image you want to save. The function returns True if the image is saved successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51f30ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('Catcopy.jpg',img_grayscale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec35847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grayscalecopy = cv2.imread('Catcopy.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf8e4c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[243 243 243]\n",
      "  [241 241 241]\n",
      "  [240 240 240]\n",
      "  ...\n",
      "  [246 246 246]\n",
      "  [246 246 246]\n",
      "  [246 246 246]]\n",
      "\n",
      " [[242 242 242]\n",
      "  [240 240 240]\n",
      "  [239 239 239]\n",
      "  ...\n",
      "  [245 245 245]\n",
      "  [245 245 245]\n",
      "  [245 245 245]]\n",
      "\n",
      " [[241 241 241]\n",
      "  [239 239 239]\n",
      "  [238 238 238]\n",
      "  ...\n",
      "  [245 245 245]\n",
      "  [245 245 245]\n",
      "  [245 245 245]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[225 233 246]\n",
      "  [222 230 243]\n",
      "  [221 229 242]\n",
      "  ...\n",
      "  [163 174 188]\n",
      "  [183 194 208]\n",
      "  [199 210 224]]\n",
      "\n",
      " [[225 233 246]\n",
      "  [222 230 243]\n",
      "  [221 229 242]\n",
      "  ...\n",
      "  [184 197 213]\n",
      "  [193 203 220]\n",
      "  [201 214 228]]\n",
      "\n",
      " [[222 230 243]\n",
      "  [220 228 241]\n",
      "  [219 227 240]\n",
      "  ...\n",
      "  [196 210 228]\n",
      "  [198 210 228]\n",
      "  [198 213 229]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_grayscalecopy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf14add",
   "metadata": {},
   "source": [
    "# Reading videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48f5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_capture = cv2.VideoCapture('Cat.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667e3237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Rate :  25 frames per second\n",
      "Frame count :  176.0\n"
     ]
    }
   ],
   "source": [
    "#Check if the video was opened successfully\n",
    "if (vid_capture.isOpened() == False):\n",
    "  print(\"Error opening the video file\")\n",
    "else:\n",
    "  # Get frame rate information\n",
    "  fps = int(vid_capture.get(5))\n",
    "  print(\"Frame Rate : \",fps,\"frames per second\") \n",
    "  # Get frame count\n",
    "  frame_count = vid_capture.get(7)\n",
    "  print(\"Frame count : \", frame_count)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71b18eb0",
   "metadata": {},
   "source": [
    "The get() method takes a single argument from an enumerated list of options documented\n",
    "https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7015cc1d",
   "metadata": {},
   "source": [
    "The vid_capture.read() method returns a tuple, where the first element is a boolean and the next element is the actual video frame.\n",
    "When the first element is True, it indicates the video stream contains a frame to read. \n",
    "\n",
    "If there is a frame to read, you can then use imshow() to display the current frame in a window, otherwise exit the loop.\n",
    "Notice that you also use the waitKey() function to pause for 20ms between video frames. Calling the waitKey() function lets you monitor the keyboard for user input. \n",
    "In this case, for example, if the user presses the ‘q’ key, you exit the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21bb20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(vid_capture.isOpened()):\n",
    "  # vCapture.read() methods returns a tuple, first element is a bool\n",
    "  # and the second is frame\n",
    " \n",
    "  ret, frame = vid_capture.read()\n",
    "  if ret == True:\n",
    "    cv2.imshow('Frame',frame)\n",
    "    k = cv2.waitKey(20)\n",
    "    # 113 is ASCII code for q key\n",
    "    if k == 113:\n",
    "      break\n",
    "  else:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1597f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the objects\n",
    "vid_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccbbf1",
   "metadata": {},
   "source": [
    "# Reading Video from a Webcam"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2441dda",
   "metadata": {},
   "source": [
    "Rather than specifying a source location for a video file or an image sequence, you simply need to give a video capture device index, as shown below. \n",
    "\n",
    "-------If your system has a built-in webcam, then the device index for the camera will be ‘0’. \n",
    "-------If you have more than one camera connected to your system, then the device index associated with each additional camera is incremented (e.g. 1, 2, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df57b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa059d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain frame size information using get() method\n",
    "frame_width = int(vid_capture.get(3))\n",
    "frame_height = int(vid_capture.get(4))\n",
    "frame_size = (frame_width,frame_height)\n",
    "fps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b5e21bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize video writer object\n",
    "output = cv2.VideoWriter('Resources/output_video_from_file.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 20, frame_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51b2955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(vid_capture.isOpened()):\n",
    "    # vid_capture.read() methods returns a tuple, first element is a bool\n",
    "\n",
    "    # and the second is frame\n",
    "    ret, frame = vid_capture.read()\n",
    "    if ret == True:\n",
    "           # Write the frame to the output files\n",
    "        output.write(frame)\n",
    "    else:\n",
    "        print('Stream disconnected')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0e8c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the objects\n",
    "vid_capture.release()\n",
    "\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05966d22",
   "metadata": {},
   "source": [
    "# Image Resizing with OpenCV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e7807a1",
   "metadata": {},
   "source": [
    "Option 1: Resizing by Specifying Width and Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "421f187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image using imread function\n",
    "image = cv2.imread('cables.jpg')\n",
    "cv2.imshow('Original Image', image)\n",
    "\n",
    "# let's downscale the image using new  width and height\n",
    "down_width = 300\n",
    "down_height = 200\n",
    "down_points = (down_width, down_height)\n",
    "resized_down = cv2.resize(image, down_points, interpolation= cv2.INTER_LINEAR)\n",
    " \n",
    "# let's upscale the image using new  width and height\n",
    "\n",
    "up_width = 600\n",
    "up_height = 400\n",
    "up_points = (up_width, up_height)\n",
    "resized_up = cv2.resize(image, up_points, interpolation= cv2.INTER_LINEAR)\n",
    " \n",
    "# Display images\n",
    "\n",
    "cv2.imshow('Resized Down by defining height and width', resized_down)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('Resized Up image by defining height and width', resized_up)\n",
    "cv2.waitKey()\n",
    "\n",
    "#press any key to close the windows\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6678b781",
   "metadata": {},
   "source": [
    "Option2: Resizing With a Scaling Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "239e1916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling Up the image 1.2 times by specifying both scaling factors\n",
    "scale_up_x = 1.2\n",
    "scale_up_y = 1.2\n",
    "\n",
    "# Scaling Down the image 0.6 times specifying a single scale factor.\n",
    "scale_down = 0.6\n",
    "\n",
    "scaled_f_down = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_LINEAR)\n",
    "scaled_f_up = cv2.resize(image, None, fx= scale_up_x, fy= scale_up_y, interpolation= cv2.INTER_LINEAR)\n",
    "# Display images\n",
    "\n",
    "cv2.imshow('Resized Down by defining height and width', scaled_f_down)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('Resized Up image by defining height and width', scaled_f_up)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c578e496",
   "metadata": {},
   "source": [
    "Option3: Resizing With Different Interpolation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e972fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Down the image 0.6 times using different Interpolation Method\n",
    "res_inter_nearest = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_NEAREST)\n",
    "res_inter_linear = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_LINEAR)\n",
    "res_inter_area = cv2.resize(image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15b135cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate images in horizontal axis for comparison\n",
    "\n",
    "vertical= np.concatenate((res_inter_nearest, res_inter_linear, res_inter_area), axis = 0)\n",
    "# Display the image Press any key to continue\n",
    "cv2.imshow('Inter Nearest :: Inter Linear :: Inter Area', vertical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950715da",
   "metadata": {},
   "source": [
    "# Cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efecc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338, 338, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "img = cv2.imread('cables.jpg')\n",
    "\n",
    "print(img.shape) # Print image shape\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "\n",
    "# Cropping an image\n",
    "cropped_image = img[80:280, 150:330]\n",
    "# Display cropped image\n",
    "\n",
    "cv2.imshow(\"cropped\", cropped_image)\n",
    "\n",
    "# Save the cropped image\n",
    "\n",
    "cv2.imwrite(\"Cropped Image.jpg\", cropped_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b137f",
   "metadata": {},
   "source": [
    "# Image Rotation using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcec4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the image\n",
    "image = cv2.imread('cables.jpg')\n",
    "#compute the rotation point, which in this example, will be the center of the image.\n",
    "# Dividing height and width by 2 to get the center of the image\n",
    "height, width = image.shape[:2]\n",
    "center = (width/2, height/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5dc7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above center is the center of rotation axis\n",
    "# use cv2.getRotationMatrix2D() to get the rotation matrix\n",
    "rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=45, scale=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "048e4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the image using cv2.warpAffine\n",
    "rotated_image = cv2.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "839303df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the original and the rotated image\n",
    "cv2.imshow('Original image', image)\n",
    "cv2.imshow('Rotated image', rotated_image)\n",
    "# wait indefinitely, press any key on keyboard to exit\n",
    "cv2.waitKey(0)\n",
    "# write the output, the rotated image to disk\n",
    "cv2.imwrite('rotated_image.jpg', rotated_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c006c9",
   "metadata": {},
   "source": [
    "# Translation of Images using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff18c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image\n",
    "image = cv2.imread('cables.jpg')\n",
    "# get the width and height of the image\n",
    "height, width = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e64a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tx and ty values for translation\n",
    "# you can specify any value of your choice\n",
    "tx, ty = width / 4, height / 4\n",
    " \n",
    "# create the translation matrix using tx and ty, it is a NumPy array\n",
    "translation_matrix = np.array([ [1, 0, tx],[0, 1, ty]], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40823f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the translation to the image\n",
    "translated_image = cv2.warpAffine(src=image, M=translation_matrix, dsize=(width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb5cef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the original and the Translated images\n",
    "cv2.imshow('Translated image', translated_image)\n",
    "cv2.imshow('Original image', image)\n",
    "cv2.waitKey(0)\n",
    "# save the translated image to disk\n",
    "cv2.imwrite('translated_image.jpg', translated_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdf715",
   "metadata": {},
   "source": [
    "# Annotating Images Using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5eb7e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the image\n",
    "image = cv2.imread('cables.jpg')\n",
    "# make a copy of the original image\n",
    "imageRectangle = img.copy()\n",
    "# define the starting and end points of the rectangle\n",
    "start_point =(50,100)\n",
    "end_point =(75,25)\n",
    "# draw the rectangle\n",
    "cv2.rectangle(imageRectangle, start_point, end_point, (0, 0, 255), thickness= 3, lineType=cv2.LINE_8)\n",
    "# display the output\n",
    "cv2.imshow('imageRectangle', imageRectangle)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86bb111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the original image\n",
    "imageText = img.copy()\n",
    "#let's write the text you want to put on the image\n",
    "text = 'These are cables!'\n",
    "#org: Where you want to put the text\n",
    "org = (50,350)\n",
    "# write the text on the input image\n",
    "cv2.putText(imageText, text, org, fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 1.5, color = (250,225,100))\n",
    "# display the output image with text over it\n",
    "cv2.imshow(\"Image Text\",imageText)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2720254",
   "metadata": {},
   "source": [
    "# Annotating Images Using the Mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c676c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the bounding box coordinates\n",
    "top_left_corner=[]\n",
    "bottom_right_corner=[]\n",
    " \n",
    "# function which will be called on mouse input\n",
    "def drawRectangle(action, x, y, flags, *userdata):\n",
    "  # Referencing global variables\n",
    "  global top_left_corner, bottom_right_corner\n",
    "  # Mark the top left corner when left mouse button is pressed\n",
    "  if action == cv2.EVENT_LBUTTONDOWN:\n",
    "    top_left_corner = [(x,y)]\n",
    "\n",
    "    # When left mouse button is released, mark bottom right corner\n",
    "  elif action == cv2.EVENT_LBUTTONUP:\n",
    "\n",
    "    bottom_right_corner = [(x,y)]   \n",
    "\n",
    "    # Draw the rectangle\n",
    "    cv2.rectangle(image, top_left_corner[0], bottom_right_corner[0], (0,255,0),2, 8)\n",
    "\n",
    "    cv2.imshow(\"Window\",image)\n",
    "# Read Images\n",
    "\n",
    "image = cv2.imread(\"cells.png\")\n",
    "\n",
    "# Make a temporary image, will be useful to clear the drawing\n",
    "\n",
    "temp = image.copy()\n",
    "\n",
    "# Create a named window\n",
    "\n",
    "cv2.namedWindow(\"Window\")\n",
    "\n",
    "# highgui function called when mouse events occur\n",
    "cv2.setMouseCallback(\"Window\", drawRectangle)\n",
    "\n",
    "k=0\n",
    "\n",
    "# Close the window when key q is pressed\n",
    "\n",
    "while k!=113:\n",
    "\n",
    "  # Display the image\n",
    "  cv2.imshow(\"Window\", image)\n",
    "  k = cv2.waitKey(0)\n",
    "\n",
    "  # If c is pressed, clear the window, using the dummy image\n",
    "\n",
    "  if (k == 99):\n",
    "\n",
    "    image= temp.copy()\n",
    "\n",
    "    cv2.imshow(\"Window\", image)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5db416",
   "metadata": {},
   "source": [
    "# Resizing an Image Using the Trackbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0052d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxScaleUp = 100\n",
    "scaleFactor = 1\n",
    "windowName = \"Resize Image\"\n",
    "trackbarValue = \"Scale\"\n",
    "# read the image\n",
    "image = cv2.imread(\"cells.jpg\")\n",
    "\n",
    "# Create a window to display results and  set the flag to Autosize (WINDOW_AUTOSIZE flag is important because it lets us resize the image)\n",
    "cv2.namedWindow(windowName, cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Callback functions (will be called when the user interacts with the trackbar)\n",
    "\n",
    "def scaleImage(*args):\n",
    "\n",
    "    # Get the scale factor from the trackbar\n",
    "    scaleFactor = 1+ args[0]/100.0\n",
    "\n",
    "    # Resize the image\n",
    "    scaledImage = cv2.resize(image, None, fx=scaleFactor, fy = scaleFactor, interpolation = cv2.INTER_LINEAR)\n",
    "    cv2.imshow(windowName, scaledImage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create trackbar and associate a callback function\n",
    "\n",
    "cv2.createTrackbar(trackbarValue, windowName, scaleFactor, maxScaleUp, scaleImage)\n",
    "\n",
    "# Display the image\n",
    "\n",
    "cv2.imshow(windowName, image)\n",
    "\n",
    "c = cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
